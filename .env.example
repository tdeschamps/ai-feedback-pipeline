# LLM Configuration
LLM_PROVIDER=openai  # openai, anthropic, ollama, groq, huggingface
LLM_MODEL=gpt-4o
LLM_BASE_URL=  # For local LLMs (e.g., http://localhost:11434 for Ollama)
OPENAI_API_KEY=your_openai_key_here
ANTHROPIC_API_KEY=your_anthropic_key_here
GROQ_API_KEY=your_groq_key_here
HUGGINGFACE_API_TOKEN=your_hf_token_here

# Embedding Configuration
EMBEDDING_PROVIDER=openai  # openai, huggingface
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536

# Vector Store Configuration
VECTOR_STORE=chromadb  # chromadb, pinecone

# ChromaDB Configuration (for local storage)
CHROMADB_HOST=localhost
CHROMADB_PORT=8000
CHROMADB_COLLECTION_NAME=feedback_embeddings
CHROMADB_PERSIST_DIRECTORY=./chroma_db

# Pinecone Configuration (for cloud storage)
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_ENVIRONMENT=your_pinecone_environment
PINECONE_INDEX_NAME=feedback-pipeline

# Notion Configuration
NOTION_API_KEY=your_notion_api_key
NOTION_DATABASE_ID=your_notion_database_id

# Pipeline Configuration
CONFIDENCE_THRESHOLD=0.7
MAX_MATCHES=5
RERANK_ENABLED=true

# Logging
LOG_LEVEL=INFO
LOG_FILE=pipeline.log
